/* This file is generated by the genmloop script.  DO NOT EDIT! */

/* Enable switch() support in cgen headers.  */
#define SEM_IN_SWITCH

#define WANT_CPU aapbf
#define WANT_CPU_AAPBF

#include "sim-main.h"
#include "bfd.h"
#include "cgen-mem.h"
#include "cgen-ops.h"
#include "sim-assert.h"

/* Fill in the administrative ARGBUF fields required by all insns,
   virtual and real.  */

static INLINE void
aapbf_fill_argbuf (const SIM_CPU *cpu, ARGBUF *abuf, const IDESC *idesc,
		    PCADDR pc, int fast_p)
{
#if WITH_SCACHE
  SEM_SET_CODE (abuf, idesc, fast_p);
  ARGBUF_ADDR (abuf) = pc;
#endif
  ARGBUF_IDESC (abuf) = idesc;
}

/* Fill in tracing/profiling fields of an ARGBUF.  */

static INLINE void
aapbf_fill_argbuf_tp (const SIM_CPU *cpu, ARGBUF *abuf,
		       int trace_p, int profile_p)
{
  ARGBUF_TRACE_P (abuf) = trace_p;
  ARGBUF_PROFILE_P (abuf) = profile_p;
}

#if WITH_SCACHE_PBB

/* Emit the "x-before" handler.
   x-before is emitted before each insn (serial or parallel).
   This is as opposed to x-after which is only emitted at the end of a group
   of parallel insns.  */

static INLINE void
aapbf_emit_before (SIM_CPU *current_cpu, SCACHE *sc, PCADDR pc, int first_p)
{
  ARGBUF *abuf = &sc[0].argbuf;
  const IDESC *id = & CPU_IDESC (current_cpu) [AAPBF_INSN_X_BEFORE];

  abuf->fields.before.first_p = first_p;
  aapbf_fill_argbuf (current_cpu, abuf, id, pc, 0);
  /* no need to set trace_p,profile_p */
}

/* Emit the "x-after" handler.
   x-after is emitted after a serial insn or at the end of a group of
   parallel insns.  */

static INLINE void
aapbf_emit_after (SIM_CPU *current_cpu, SCACHE *sc, PCADDR pc)
{
  ARGBUF *abuf = &sc[0].argbuf;
  const IDESC *id = & CPU_IDESC (current_cpu) [AAPBF_INSN_X_AFTER];

  aapbf_fill_argbuf (current_cpu, abuf, id, pc, 0);
  /* no need to set trace_p,profile_p */
}

#endif /* WITH_SCACHE_PBB */

static INLINE const IDESC *
extract (SIM_CPU *current_cpu, PCADDR pc, CGEN_INSN_INT insn, ARGBUF *abuf,
         int fast_p)
{
  const IDESC *id = aapbf_aap_decode (current_cpu, pc, insn,
#if CGEN_INT_INSN_P
				  insn,
#endif
				  abuf);
  aapbf_fill_argbuf (current_cpu, abuf, id, pc, fast_p);
  if (! fast_p)
    {
      int trace_p = PC_IN_TRACE_RANGE_P (current_cpu, pc);
      int profile_p = PC_IN_PROFILE_RANGE_P (current_cpu, pc);
      aapbf_fill_argbuf_tp (current_cpu, abuf, trace_p, profile_p);
    }
  return id;
}

static INLINE SEM_PC
execute (SIM_CPU *current_cpu, SCACHE *sc, int fast_p)
{
  SEM_PC vpc;

  if (fast_p)
    {
#if ! WITH_SEM_SWITCH_FAST
#if WITH_SCACHE
      vpc = (*sc->argbuf.semantic.sem_fast) (current_cpu, sc);
#else
      vpc = (*sc->argbuf.semantic.sem_fast) (current_cpu, &sc->argbuf);
#endif
#else
      abort ();
#endif /* WITH_SEM_SWITCH_FAST */
    }
  else
    {
#if ! WITH_SEM_SWITCH_FULL
      ARGBUF *abuf = &sc->argbuf;
      const IDESC *idesc = abuf->idesc;
#if WITH_SCACHE_PBB
      int virtual_p = CGEN_ATTR_VALUE (NULL, idesc->attrs, CGEN_INSN_VIRTUAL);
#else
      int virtual_p = 0;
#endif

      if (! virtual_p)
	{
	  /* FIXME: call x-before */
	  if (ARGBUF_PROFILE_P (abuf))
	    PROFILE_COUNT_INSN (current_cpu, abuf->addr, idesc->num);
	  /* FIXME: Later make cover macros: PROFILE_INSN_{INIT,FINI}.  */
	  if (PROFILE_MODEL_P (current_cpu)
	      && ARGBUF_PROFILE_P (abuf))
	    aapbf_model_insn_before (current_cpu, 1 /*first_p*/);
	  TRACE_INSN_INIT (current_cpu, abuf, 1);
	  TRACE_INSN (current_cpu, idesc->idata,
		      (const struct argbuf *) abuf, abuf->addr);
	}
#if WITH_SCACHE
      vpc = (*sc->argbuf.semantic.sem_full) (current_cpu, sc);
#else
      vpc = (*sc->argbuf.semantic.sem_full) (current_cpu, abuf);
#endif
      if (! virtual_p)
	{
	  /* FIXME: call x-after */
	  if (PROFILE_MODEL_P (current_cpu)
	      && ARGBUF_PROFILE_P (abuf))
	    {
	      int cycles;

	      cycles = (*idesc->timing->model_fn) (current_cpu, sc);
	      aapbf_model_insn_after (current_cpu, 1 /*last_p*/, cycles);
	    }
	  TRACE_INSN_FINI (current_cpu, abuf, 1);
	}
#else
      abort ();
#endif /* WITH_SEM_SWITCH_FULL */
    }

  return vpc;
}


static INLINE SCACHE *
aapbf_scache_lookup (SIM_CPU *current_cpu, PCADDR vpc, SCACHE *scache,
                     unsigned int hash_mask, int FAST_P)
{
  /* First step: look up current insn in hash table.  */
  SCACHE *sc = scache + SCACHE_HASH_PC (vpc, hash_mask);

  /* If the entry isn't the one we want (cache miss),
     fetch and decode the instruction.  */
  if (sc->argbuf.addr != vpc)
    {
      if (! FAST_P)
	PROFILE_COUNT_SCACHE_MISS (current_cpu);

/* begin extract-scache */
{
  CGEN_INSN_INT insn = GETIMEMUHI (current_cpu, vpc);
  extract (current_cpu, vpc, insn, SEM_ARGBUF (sc), FAST_P);
}
/* end extract-scache */
    }
  else if (! FAST_P)
    {
      PROFILE_COUNT_SCACHE_HIT (current_cpu);
      /* Make core access statistics come out right.
	 The size is a guess, but it's currently not used either.  */
      PROFILE_COUNT_CORE (current_cpu, vpc, 2, exec_map);
    }

  return sc;
}

#define FAST_P 0

void
aapbf_engine_run_full (SIM_CPU *current_cpu)
{
  SIM_DESC current_state = CPU_STATE (current_cpu);
  SCACHE *scache = CPU_SCACHE_CACHE (current_cpu);
  unsigned int hash_mask = CPU_SCACHE_HASH_MASK (current_cpu);
  SEM_PC vpc;


  if (! CPU_IDESC_SEM_INIT_P (current_cpu))
    {
#if ! WITH_SEM_SWITCH_FULL
      aapbf_aap_sem_init_idesc_table (current_cpu);
#endif
      CPU_IDESC_SEM_INIT_P (current_cpu) = 1;
    }

  vpc = GET_H_PC ();

  do
    {
      SCACHE *sc;

      sc = aapbf_scache_lookup (current_cpu, vpc, scache, hash_mask, FAST_P);

/* begin full-exec-scache */
{
#if (! FAST_P && WITH_SEM_SWITCH_FULL) || (FAST_P && WITH_SEM_SWITCH_FAST)
#define DEFINE_SWITCH
#include "semaapbf-switch.c"
#else
  vpc = execute (current_cpu, vpc, FAST_P);
#endif
}
/* end full-exec-scache */

      SET_H_PC (vpc);

      ++ CPU_INSN_COUNT (current_cpu);
    }
  while (0 /*CPU_RUNNING_P (current_cpu)*/);
}

#undef FAST_P

